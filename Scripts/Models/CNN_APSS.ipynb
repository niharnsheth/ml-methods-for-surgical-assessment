{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31e05a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "## --- Libraries   ---  ##\n",
    "# File imports and aggregates data from multiple databases\n",
    "import os\n",
    "import fnmatch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "# from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv1D\n",
    "from tensorflow.keras.layers import MaxPool1D\n",
    "from tensorflow.keras.layers import GlobalAvgPool1D, Flatten\n",
    "# from tensorflow.keras.regularizers import l2\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d627c9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path to + the database files\n",
    "# source_path = os.getcwd() + '/../../Nihar/ML-data/SurgicalData'\n",
    "# source_path = os.getcwd() + '/../../../../Nihar/ML-data/SurgicalData/Data_04152021'\n",
    "# source_path = os.getcwd() + '/../../../../Nihar/ML-data/SurgicalData/ManuallyCleaned_06262021'\n",
    "source_path = os.getcwd() + '/../../../../Nihar/ML-data/SurgicalData/Manually_Cleaned_And_Annotated_06272021'\n",
    "\n",
    "surgery_selected = 0\n",
    "# action_selected = 2\n",
    "\n",
    "# surgery_name_list = ['/Pericardiocentesis', '/Thoracentesis']\n",
    "surgery_name_list = ['/Pericardiocentesis', '/Thoracentesis']\n",
    "action_name_list = [['Chloraprep', 'Needle Insertion'],\n",
    "                    ['Chloraprep', 'Scalpel Incision', 'Trocar Insertion', 'Anesthetization']]\n",
    "# surgery_name_list = ['/Thoracentesis']\n",
    "input_folder = '/TrainingDataForClassification'\n",
    "save_to_folder = '/Results/1D_CNN'\n",
    "save_model = '/08092021_refCNN_w180'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21696d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  ---  Define hyper parameters  ---  #\n",
    "skill_levels = 3\n",
    "\n",
    "no_sensors = 1\n",
    "features_per_sensor = 13\n",
    "num_of_labels = 3\n",
    "n_features = no_sensors * features_per_sensor\n",
    "n_classes = 3  # number of outputs for classification\n",
    "\n",
    "# ------------- ideal training values  ---------------- #\n",
    "# epochs = [[50, 50], [50, 50, 75, 50]]\n",
    "# sliding_window = [[100, 175], [100, 80, 175, 150]]\n",
    "# batch_size = [[75, 125], [150, 75, 100, 125]]\n",
    "# ----------------------------------------------------#\n",
    "\n",
    "epochs = [[100, 100], [100, 100, 100, 100]]\n",
    "sliding_window = [[180, 180], [180, 180, 180, 180]]\n",
    "window_step_size = 1\n",
    "batch_size = [[100, 100], [100, 100, 100, 100]]\n",
    "learning_rate = 0.001\n",
    "set_rand_seed = 11\n",
    "random.seed(set_rand_seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9f18de",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  ---   Make motion windows   --- #\n",
    "# return an input and output data frame with motion windows\n",
    "def create_motion_windows(window_span, df_to_change, step_size, number_of_features, number_of_labels):\n",
    "    local_feature_df = []\n",
    "    local_label_df = []\n",
    "    # steps = range(len(df_to_change) - window_span)\n",
    "    time_index = 0\n",
    "    while time_index + window_span < len(df_to_change):\n",
    "        feat_local = df_to_change.iloc[time_index:time_index + window_span, :-number_of_labels].reset_index(drop=True).to_numpy()\n",
    "        # a.reset_index(drop=True)\n",
    "        lab_loc = df_to_change.iloc[time_index + window_span, number_of_features:].reset_index(drop=True).to_numpy()\n",
    "        local_feature_df.append(feat_local)\n",
    "        local_label_df.append(lab_loc)\n",
    "        time_index += step_size\n",
    "    return local_feature_df, local_label_df\n",
    "\n",
    "\n",
    "# Return index for annotation\n",
    "def check_experience_level(experience):\n",
    "    if fnmatch.fnmatch(experience, 'Novice'):\n",
    "        return 0\n",
    "    elif fnmatch.fnmatch(experience, 'Intermediate'):\n",
    "        return 1\n",
    "    elif fnmatch.fnmatch(experience, 'Expert'):\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f77a8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## ----------------- FINALIZED  CNN 1D ----------------------------------------- #\n",
    "#\n",
    "# # --- tf.Keras implementation of LSTM layers --- #\n",
    "# model = Sequential()\n",
    "# model.add(Conv1D(filters=38, kernel_size=2, activation='relu', input_shape=(None, n_features)))\n",
    "# model.add(MaxPool1D(pool_size=2, strides=2))\n",
    "# model.add(Dropout(0.25))\n",
    "# model.add(Conv1D(filters=76, kernel_size=2, activation='relu'))\n",
    "# model.add(MaxPool1D(pool_size=2, strides=2))\n",
    "# model.add(Dropout(0.25))\n",
    "# model.add(Conv1D(filters=152, kernel_size=2, activation='relu'))\n",
    "# model.add(MaxPool1D(pool_size=2, strides=2))\n",
    "# model.add(Dropout(0.25))\n",
    "# model.add(Conv1D(filters=304, kernel_size=2, activation='relu'))\n",
    "# model.add(MaxPool1D(pool_size=2, strides=2))\n",
    "# model.add(Dropout(0.25))\n",
    "# # model.add(Flatten())\n",
    "# model.add(GlobalAvgPool1D())\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(152, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(38, activation='relu'))\n",
    "# model.add(Dense(n_classes, activation='softmax'))\n",
    "# opt = tf.keras.optimizers.Adam(lr=learning_rate, decay=1e-3)\n",
    "#\n",
    "# model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "#\n",
    "\n",
    "## ----------------- REFERENCE  CNN 1D ----------------------------------------- #\n",
    "# --- tf.Keras implementation of LSTM layers --- #\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=38, kernel_size=2, activation='relu', input_shape=(180, n_features)))\n",
    "model.add(MaxPool1D(pool_size=2, strides=2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(filters=76, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPool1D(pool_size=2, strides=2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv1D(filters=152, kernel_size=2, activation='relu'))\n",
    "model.add(MaxPool1D(pool_size=2, strides=2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(n_classes, activation='softmax'))\n",
    "opt = tf.keras.optimizers.Adam(lr=learning_rate, decay=1e-3)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55f2e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "## --- Training process  ---  #\n",
    "print(' ------------- Training   ------------')\n",
    "\n",
    "# Create folder to save the model and results\n",
    "os.mkdir(source_path + save_to_folder + save_model)\n",
    "# Create folder to save all the plots\n",
    "os.mkdir(source_path + save_to_folder + save_model + '/' + 'Graphs')\n",
    "# train for all surgical procedures\n",
    "for surgery_selected in range(0, len(surgery_name_list)):\n",
    "    manually_annotated_labels = pd.read_csv(source_path + \"/\" + surgery_name_list[surgery_selected][1:] + \".csv\")\n",
    "\n",
    "    # train for each surgical task with procedure\n",
    "    surgical_tasks = os.listdir(source_path + input_folder + surgery_name_list[surgery_selected] + '/')\n",
    "    for action_selected in range(len(surgical_tasks)):\n",
    "        print(\"Surgery: \" + surgery_name_list[surgery_selected] + \" -  Action: \" + surgical_tasks[action_selected])\n",
    "        # get data of surgical tasks\n",
    "        csv_list = [f for f in os.listdir(source_path + input_folder +\n",
    "                                          surgery_name_list[surgery_selected] + '/' +\n",
    "                                          surgical_tasks[action_selected] + '/')\n",
    "                    if fnmatch.fnmatch(f, '*.csv')]\n",
    "\n",
    "        # initialize input and output list\n",
    "        feature_list_main = [[] for _ in range(3)]\n",
    "        label_list_main = [[] for _ in range(3)]\n",
    "\n",
    "        # train for surgical task\n",
    "        for file in csv_list:\n",
    "            # read the file into a data-frame\n",
    "            df = pd.read_csv(source_path + input_folder +\n",
    "                             surgery_name_list[surgery_selected] +\n",
    "                             '/' + surgical_tasks[action_selected] +\n",
    "                             '/' + file)\n",
    "            check_if_null = df.isnull().values.any()\n",
    "            print(file + \" has null values: \" + str(check_if_null))\n",
    "            df = df.dropna(how='any', axis=0)\n",
    "\n",
    "            # Get experience level\n",
    "            file_idx = manually_annotated_labels.index[manually_annotated_labels['PerformanceName'] == file[:-4]]\n",
    "            experience_level = manually_annotated_labels.iloc[file_idx][surgical_tasks[action_selected]].iloc[0]\n",
    "            exp_index = check_experience_level(experience_level)\n",
    "            # # Get experience level\n",
    "            # split_list = file.split('_')\n",
    "            # experience_level = split_list[1]\n",
    "            # exp_index = check_experience_level(experience_level)\n",
    "\n",
    "            # create motion windows and separate data into input and output\n",
    "            # feature_list, label_list = create_motion_windows(random.choice(sliding_window_2), df)\n",
    "            feature_list, label_list = create_motion_windows(sliding_window[surgery_selected][action_selected], df,\n",
    "                                                             window_step_size,\n",
    "                                                             features_per_sensor,\n",
    "                                                             num_of_labels)\n",
    "\n",
    "            # create list of windows\n",
    "            feature_list_main[exp_index].extend(feature_list)\n",
    "            label_list_main[exp_index].extend(label_list)\n",
    "        # count number of windows for each class\n",
    "        a = []\n",
    "        for i in range(len(feature_list_main)):\n",
    "            a.append(len(feature_list_main[i]))\n",
    "            print(\"Number of windows: \" + str(len(feature_list_main[i])))\n",
    "        min_window = min(a)\n",
    "\n",
    "        # randomly select min_windows from each class\n",
    "        print(\"Length of feature list: \" + str(len(feature_list_main)))\n",
    "        for i in range(len(feature_list_main)):\n",
    "            if min_window != len(feature_list_main[i]):\n",
    "                feature_list_main[i] = random.choices(feature_list_main[i], k=min_window)\n",
    "                label_list_main[i] = label_list_main[i][0:min_window]\n",
    "\n",
    "        # combine all lists to one\n",
    "        input_feature_list = []\n",
    "        output_label_list = []\n",
    "        input_feature_list.extend(feature_list_main[0])\n",
    "        input_feature_list.extend(feature_list_main[1])\n",
    "        input_feature_list.extend(feature_list_main[2])\n",
    "        output_label_list.extend(label_list_main[0])\n",
    "        output_label_list.extend(label_list_main[1])\n",
    "        output_label_list.extend(label_list_main[2])\n",
    "        feature_list_main.clear()\n",
    "        label_list_main.clear()\n",
    "\n",
    "        # shuffle data before training model\n",
    "        combined_list = list(zip(input_feature_list, output_label_list))\n",
    "        random.shuffle(combined_list)\n",
    "        input_feature_list, output_label_list = zip(*combined_list)\n",
    "        combined_list.clear()\n",
    "\n",
    "        # reshape to train\n",
    "        input_feature_list = np.reshape(input_feature_list,\n",
    "                                        (len(input_feature_list),\n",
    "                                         sliding_window[surgery_selected][action_selected],\n",
    "                                         n_features))\n",
    "        input_feature_list = np.array(input_feature_list)\n",
    "        output_label_list = np.array(output_label_list)\n",
    "        # get total number of batches\n",
    "        total_motion_n_windows = len(input_feature_list)\n",
    "        print(\"Total no. of motion windows for: \" + surgery_name_list[surgery_selected][1:] +\n",
    "              '- ' + surgical_tasks[action_selected] + ': ' + str(total_motion_n_windows))\n",
    "\n",
    "        n_batches = int(total_motion_n_windows / batch_size[surgery_selected][action_selected])\n",
    "        print(\"Total no. of batches for: \" + surgery_name_list[surgery_selected][1:] +\n",
    "              '- ' + surgical_tasks[action_selected] + ': ' + str(n_batches))\n",
    "\n",
    "        # split data for training and testing\n",
    "        x_train, x_test, y_train, y_test = train_test_split(input_feature_list, output_label_list, test_size=0.15, random_state=set_rand_seed)\n",
    "        # train\n",
    "        history = model.fit(x_train, y_train,\n",
    "                            epochs=epochs[surgery_selected][action_selected],\n",
    "                            batch_size=batch_size[surgery_selected][action_selected],\n",
    "                            validation_split=0.15,\n",
    "                            verbose=2)\n",
    "        # display summary of training\n",
    "        model.summary()\n",
    "\n",
    "        # plot losses\n",
    "        plt.plot(history.history['loss'], label='loss')\n",
    "        plt.plot(history.history['val_loss'], label='val_loss')\n",
    "        plt.title('Model loss - ' + surgery_name_list[surgery_selected] +\n",
    "                  ' - ' + action_name_list[surgery_selected][action_selected])\n",
    "        plt.ylabel('loss value')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(loc=\"upper left\")\n",
    "        plt.savefig(source_path + save_to_folder + save_model + '/' + 'Graphs' + '/' +\n",
    "                    surgery_name_list[surgery_selected][1:] + '_' + str(action_selected) + '_' + 'loss' + '.png',\n",
    "                    dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "        # plot accuracies\n",
    "        plt.plot(history.history['accuracy'], label='acc')\n",
    "        plt.plot(history.history['val_accuracy'], label='val_acc')\n",
    "        plt.title('Model accuracy' + surgery_name_list[surgery_selected] +\n",
    "                  ' - ' + action_name_list[surgery_selected][action_selected])\n",
    "        plt.ylabel('accuracy value')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(loc=\"upper left\")\n",
    "        plt.savefig(source_path + save_to_folder + save_model + '/' + 'Graphs' + '/' +\n",
    "                    surgery_name_list[surgery_selected][1:] + '_' + str(action_selected) + '_' + 'acc' + '.png',\n",
    "                    dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "        # test the model\n",
    "        model.evaluate(x_test, y_test, batch_size=n_batches, verbose=2)\n",
    "\n",
    "        # Create folder to save trained model\n",
    "        os.mkdir(source_path + save_to_folder + save_model + '/' +\n",
    "                 surgery_name_list[surgery_selected] + '_' + str(action_selected))\n",
    "        # save the trained model\n",
    "        model.save(source_path + save_to_folder + save_model +\n",
    "                   '/' + surgery_name_list[surgery_selected] +\n",
    "                   '_' + str(action_selected) + '/', save_format='tf')\n",
    "\n",
    "        # save the history of training to csv file\n",
    "        train_hist_df = pd.DataFrame(history.history)\n",
    "        train_hist_df.to_csv(source_path + save_to_folder + save_model + '/'\n",
    "                             + surgery_name_list[surgery_selected] + '_'\n",
    "                             + str(action_selected) + '/'\n",
    "                             + action_name_list[surgery_selected][action_selected] + '.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unity_python_zeromq",
   "language": "python",
   "name": "unity_python_zeromq"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
